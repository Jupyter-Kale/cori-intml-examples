{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras + horovod + ipyparallel MNIST example\n",
    "\n",
    "In this notebook we will use ipyparallel to deploy a Keras + Horovod distributed training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "# External imports\n",
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ipyparallel cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default profile for now\n",
    "c = ipp.Client()\n",
    "print('Worker IDs:', c.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize environment on the workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import socket\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Horovod for MPI synchronization routines\n",
    "import horovod.keras as hvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] MPI rank 3, local rank 0, host nid00027\n",
      "[stdout:1] MPI rank 1, local rank 0, host nid00019\n",
      "[stdout:2] MPI rank 2, local rank 0, host nid00020\n",
      "[stdout:3] MPI rank 0, local rank 0, host nid00018\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# Initialize horovod\n",
    "hvd.init()\n",
    "print('MPI rank %i, local rank %i, host %s' %\n",
    "      (hvd.rank(), hvd.local_rank(), socket.gethostname()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# Data config\n",
    "n_classes = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Training config\n",
    "batch_size = 128\n",
    "n_epochs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data on each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:1] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:2] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:3] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Scale pixels to [0, 1]\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:3] \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# Adjust learning rate based on number of workers.\n",
    "opt = keras.optimizers.Adadelta(1.0 * hvd.size())\n",
    "\n",
    "# Add Horovod Distributed Optimizer.\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if hvd.rank() == 0:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed training\n",
    "\n",
    "Training with horovod + MPI allows for synchronous distributed batch updates.\n",
    "\n",
    "We need to register the model synchronization callback and restrict checkpoint writing to a single worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.1734 - acc: 0.9467 - val_loss: 0.0340 - val_acc: 0.9887\n",
      "Epoch 2/8\n",
      " - 28s - loss: 0.0453 - acc: 0.9853 - val_loss: 0.0297 - val_acc: 0.9895\n",
      "Epoch 3/8\n",
      " - 27s - loss: 0.0300 - acc: 0.9906 - val_loss: 0.0274 - val_acc: 0.9917\n",
      "Epoch 4/8\n",
      " - 28s - loss: 0.0222 - acc: 0.9928 - val_loss: 0.0253 - val_acc: 0.9928\n",
      "Epoch 5/8\n",
      " - 27s - loss: 0.0173 - acc: 0.9946 - val_loss: 0.0341 - val_acc: 0.9918\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.0146 - acc: 0.9951 - val_loss: 0.0348 - val_acc: 0.9911\n",
      "Epoch 7/8\n",
      " - 27s - loss: 0.0119 - acc: 0.9958 - val_loss: 0.0303 - val_acc: 0.9932\n",
      "Epoch 8/8\n",
      " - 27s - loss: 0.0107 - acc: 0.9963 - val_loss: 0.0299 - val_acc: 0.9934\n",
      "[stdout:1] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 28s - loss: 0.1730 - acc: 0.9472 - val_loss: 0.0340 - val_acc: 0.9887\n",
      "Epoch 2/8\n",
      " - 28s - loss: 0.0455 - acc: 0.9859 - val_loss: 0.0297 - val_acc: 0.9895\n",
      "Epoch 3/8\n",
      " - 27s - loss: 0.0284 - acc: 0.9908 - val_loss: 0.0274 - val_acc: 0.9917\n",
      "Epoch 4/8\n",
      " - 28s - loss: 0.0232 - acc: 0.9919 - val_loss: 0.0253 - val_acc: 0.9928\n",
      "Epoch 5/8\n",
      " - 27s - loss: 0.0189 - acc: 0.9935 - val_loss: 0.0341 - val_acc: 0.9918\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0348 - val_acc: 0.9911\n",
      "Epoch 7/8\n",
      " - 27s - loss: 0.0129 - acc: 0.9957 - val_loss: 0.0303 - val_acc: 0.9932\n",
      "Epoch 8/8\n",
      " - 27s - loss: 0.0117 - acc: 0.9958 - val_loss: 0.0299 - val_acc: 0.9934\n",
      "[stdout:2] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 28s - loss: 0.1738 - acc: 0.9471 - val_loss: 0.0340 - val_acc: 0.9887\n",
      "Epoch 2/8\n",
      " - 28s - loss: 0.0443 - acc: 0.9867 - val_loss: 0.0297 - val_acc: 0.9895\n",
      "Epoch 3/8\n",
      " - 27s - loss: 0.0288 - acc: 0.9908 - val_loss: 0.0274 - val_acc: 0.9917\n",
      "Epoch 4/8\n",
      " - 28s - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0253 - val_acc: 0.9928\n",
      "Epoch 5/8\n",
      " - 27s - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0341 - val_acc: 0.9918\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.0154 - acc: 0.9948 - val_loss: 0.0348 - val_acc: 0.9911\n",
      "Epoch 7/8\n",
      " - 27s - loss: 0.0125 - acc: 0.9960 - val_loss: 0.0303 - val_acc: 0.9932\n",
      "Epoch 8/8\n",
      " - 27s - loss: 0.0113 - acc: 0.9962 - val_loss: 0.0299 - val_acc: 0.9934\n",
      "[stdout:3] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 29s - loss: 0.1758 - acc: 0.9465 - val_loss: 0.0340 - val_acc: 0.9887\n",
      "Epoch 2/8\n",
      " - 28s - loss: 0.0450 - acc: 0.9862 - val_loss: 0.0297 - val_acc: 0.9895\n",
      "Epoch 3/8\n",
      " - 27s - loss: 0.0306 - acc: 0.9906 - val_loss: 0.0274 - val_acc: 0.9917\n",
      "Epoch 4/8\n",
      " - 27s - loss: 0.0227 - acc: 0.9926 - val_loss: 0.0253 - val_acc: 0.9928\n",
      "Epoch 5/8\n",
      " - 28s - loss: 0.0174 - acc: 0.9942 - val_loss: 0.0341 - val_acc: 0.9918\n",
      "Epoch 6/8\n",
      " - 28s - loss: 0.0148 - acc: 0.9949 - val_loss: 0.0348 - val_acc: 0.9911\n",
      "Epoch 7/8\n",
      " - 27s - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0303 - val_acc: 0.9932\n",
      "Epoch 8/8\n",
      " - 27s - loss: 0.0110 - acc: 0.9960 - val_loss: 0.0299 - val_acc: 0.9934\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "callbacks = [\n",
    "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "    # This is necessary to ensure consistent initialization of all workers when\n",
    "    # training is started with random weights or restored from a checkpoint.\n",
    "    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "]\n",
    "\n",
    "# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\n",
    "#if hvd.rank() == 0:\n",
    "#    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=n_epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Test loss: 0.029908974236061068\n",
      "Test accuracy: 0.9934\n",
      "[stdout:1] \n",
      "Test loss: 0.029908974236061068\n",
      "Test accuracy: 0.9934\n",
      "[stdout:2] \n",
      "Test loss: 0.029908974236061068\n",
      "Test accuracy: 0.9934\n",
      "[stdout:3] \n",
      "Test loss: 0.029908974236061068\n",
      "Test accuracy: 0.9934\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ipp",
   "language": "python",
   "name": "python3-ipp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
