{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATLAS RPV CNN Classifier notebook\n",
    "\n",
    "Mostly taken from Michela's Keras implementation here: https://github.com/mickypaganini/susy_rpv/blob/micky/train.py\n",
    "\n",
    "* TODO: improve documentation.\n",
    "* TODO: add some relevant callbacks such as early stopping.\n",
    "* TODO: run on a full Haswell batch node.\n",
    "* TODO: tinker with the TF thread settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device and concurrency settings\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/common/software/tensorflow/intel-tensorflow/1.8.0-rc1-py27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from keras import layers, models, callbacks\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data config\n",
    "n_train = 64000 #412416\n",
    "n_valid = 32000 #137471\n",
    "n_test = 32000 #137471"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/global/cscratch1/sd/sfarrell/atlas-rpv-images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.8G\r\n",
      "-rw-rw---- 1 sfarrell sfarrell 358M Apr 24 14:32 \u001b[0m\u001b[00mtest.h5\u001b[0m\r\n",
      "-rw-rw---- 1 sfarrell sfarrell 1.1G Apr 24 14:32 \u001b[00mtrain.h5\u001b[0m\r\n",
      "-rw-rw---- 1 sfarrell sfarrell 358M Apr 24 14:32 \u001b[00mval.h5\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh $input_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file, n_samples):\n",
    "    print('Loading file', file)\n",
    "    with h5py.File(file) as f:\n",
    "        data_group = f['all_events']\n",
    "        print('Loading %i/%i events' %\n",
    "              (n_samples, data_group['hist'].shape[0]))\n",
    "        data = data_group['hist'][:n_samples][:,:,:,None]\n",
    "        labels = data_group['y'][:n_samples]\n",
    "        weights = data_group['weight'][:n_samples]\n",
    "    return data, labels, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file /global/cscratch1/sd/sfarrell/atlas-rpv-images/train.h5\n",
      "Loading 64000/412416 events\n",
      "Loading file /global/cscratch1/sd/sfarrell/atlas-rpv-images/val.h5\n",
      "Loading 32000/137471 events\n",
      "Loading file /global/cscratch1/sd/sfarrell/atlas-rpv-images/test.h5\n",
      "Loading 32000/137471 events\n",
      "CPU times: user 25.5 s, sys: 2.34 s, total: 27.8 s\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_file = os.path.join(input_dir, 'train.h5')\n",
    "valid_file = os.path.join(input_dir, 'val.h5')\n",
    "test_file = os.path.join(input_dir, 'test.h5')\n",
    "\n",
    "train_input, train_labels, train_weights = load_file(train_file, n_train)\n",
    "valid_input, valid_labels, valid_weights = load_file(valid_file, n_valid)\n",
    "test_input, test_labels, test_weights = load_file(test_file, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (64000, 64, 64, 1)\n",
      "valid shape: (32000, 64, 64, 1)\n",
      "test shape:  (32000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print('train shape:', train_input.shape)\n",
    "print('valid shape:', valid_input.shape)\n",
    "print('test shape: ', test_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, optimizer='Nadam',\n",
    "                h1=64, h2=128, h3=256, h4=256, h5=512):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    h = layers.Conv2D(h1, kernel_size=(3, 3), activation='relu', strides=1, padding='same')(inputs)\n",
    "    h = layers.Conv2D(h2, kernel_size=(3, 3), activation='relu', strides=2, padding='same')(h)\n",
    "    h = layers.Conv2D(h3, kernel_size=(3, 3), activation='relu', strides=1, padding='same')(h)\n",
    "    h = layers.Conv2D(h4, kernel_size=(3, 3), activation='relu', strides=2, padding='same')(h)\n",
    "    h = layers.Flatten()(h)\n",
    "    h = layers.Dense(h5, activation='relu')(h)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(h)\n",
    "    model = models.Model(inputs, outputs, 'RPVClassifier')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "h1, h2, h3, h4, h5 = 64, 128, 256, 256, 512\n",
    "optimizer = 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "batch_size = 256\n",
    "n_epochs = 8\n",
    "use_weights = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               33554944  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 34,515,201\n",
      "Trainable params: 34,515,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(train_input.shape[1:],\n",
    "                    h1=h1, h2=h2, h3=h3, h4=h4, h5=h5,\n",
    "                    optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_args = dict(x=train_input, y=train_labels,\n",
    "                batch_size=batch_size, epochs=n_epochs,\n",
    "                validation_data=(valid_input, valid_labels))\n",
    "if use_weights:\n",
    "    fit_args.update(sample_weight=train_weights,\n",
    "                    validation_data=(valid_input, valid_labels, valid_weights))\n",
    "history = model.fit(**fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.epoch, history.history['loss'], label='Training loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='Validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.subplot(122)\n",
    "plt.plot(history.epoch, history.history['acc'], label='Training accuracy')\n",
    "plt.plot(history.epoch, history.history['val_acc'], label='Validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_metrics(labels, outputs, threshold=0.5, weights=None):\n",
    "    preds = outputs > threshold\n",
    "    print('Metrics summaries with threshold of %.3f' % threshold)\n",
    "    print('Accuracy:   %.4f' % metrics.accuracy_score(labels, preds, sample_weight=weights))\n",
    "    print('Purity:     %.4f' % metrics.precision_score(labels, preds, sample_weight=weights))\n",
    "    print('Efficiency: %.4f' % metrics.recall_score(labels, preds, sample_weight=weights))\n",
    "\n",
    "def draw_roc(labels, outputs, weights=None, ax=None):\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, outputs, sample_weight=weights)\n",
    "    auc = metrics.roc_auc_score(labels, outputs, sample_weight=weights)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, label='CNN, AUC=%.3f' % auc)\n",
    "    ax.plot([0, 1], [0, 1], '--', label='Random')\n",
    "    ax.set_xlabel('False positive rate')\n",
    "    ax.set_ylabel('True positive rate')\n",
    "    ax.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = model.predict(test_input)\n",
    "test_output = test_output.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unweighted results\n",
    "summarize_metrics(test_labels, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted results\n",
    "summarize_metrics(test_labels, test_output, weights=test_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(9,4))\n",
    "draw_roc(test_labels, test_output, ax=axs[0])\n",
    "draw_roc(test_labels, test_output, ax=axs[1], weights=test_weights)\n",
    "axs[0].set_xlim([0, 0.01])\n",
    "axs[0].set_title('Unweighted')\n",
    "axs[1].set_xlim([0, 0.01])\n",
    "axs[1].set_title('Weighted')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model output\n",
    "plt.figure()\n",
    "\n",
    "# Select real/fake sample model outputs\n",
    "real_idx = test_labels > 0.5\n",
    "fake_idx = (real_idx == False)\n",
    "\n",
    "binning=dict(bins=100, range=(0, 1), log=True)\n",
    "plt.hist(test_output[fake_idx], weights=test_weights[fake_idx], label='Fake', **binning)\n",
    "plt.hist(test_output[real_idx], weights=test_weights[real_idx], label='Real', **binning)\n",
    "plt.legend(loc=0);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2, TF 1.8rc1",
   "language": "python",
   "name": "tf-1.8.0rc1-py27"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
